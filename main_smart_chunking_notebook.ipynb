{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation and Imports"
      ],
      "metadata": {
        "id": "q6HCH042til4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install wandb\n",
        "!pip install cohere\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "JJsHYwn8Hu6v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "KmjUo0nUH0TL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe0e2f9-09bc-4e51-aa63-326feb01a83c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lKJhO0ZEF14",
        "outputId": "ad3634d9-828f-479d-fbc1-f5a93132161a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MRj0nvwac6gZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212a8854-e4a1-4a7c-f723-044d8be22075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
            "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
            "* 'smart_union' has been removed\n",
            "  warnings.warn(message, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "# Required Imports\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import tqdm\n",
        "import wandb\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions import Categorical\n",
        "from transformers import AutoModel, AutoTokenizer, T5EncoderModel\n",
        "import cohere\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2LAXSe4G7bg"
      },
      "source": [
        "# Preparing the dataset for model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR_9It7JECc9",
        "outputId": "ece247d3-88d2-4d0b-99e1-b6361f9c8da6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(442, list)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "json_file = \"/content/drive/MyDrive/Research: Elan<>Krupa/processed_squad.json\"\n",
        "\n",
        "with open(json_file, \"r\") as f:\n",
        "  data = json.load(f)\n",
        "len(data), type(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BmMEF8TtcmP",
        "outputId": "23f35152-5f31-489a-9743-d4de74471fdb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['title', 'context', 'qas', 'sentences'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBcMFU-it4d0",
        "outputId": "3653779d-81f2-4891-92e4-6b669dacc336"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': 'University_of_Notre_Dame',\n",
              " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary. As at most other universities, Notre Dame\\'s students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artwork. The Dome yearbook is published annually. The newspapers have varying publication interests, with The Observer published daily and mainly reporting university and other news, and staffed by students from both Notre Dame and Saint Mary\\'s College. Unlike Scholastic and The Dome, The Observer is an independent publication and does not have a faculty advisor or any editorial oversight from the University. In 1987, when some students believed that The Observer began to show a conservative bias, a liberal newspaper, Common Sense was published. Likewise, in 2003, when other students believed that the paper showed a liberal bias, the conservative paper Irish Rover went into production. Neither paper is published as often as The Observer; however, all three are distributed to all students. Finally, in Spring 2008 an undergraduate journal for political science research, Beyond Politics, made its debut. The university is the major seat of the Congregation of Holy Cross (albeit not its official headquarters, which are in Rome). Its main seminary, Moreau Seminary, is located on the campus across St. Joseph lake from the Main Building. Old College, the oldest building on campus and located near the shore of St. Mary lake, houses undergraduate seminarians. Retired priests and brothers reside in Fatima House (a former retreat center), Holy Cross House, as well as Columba Hall near the Grotto. The university through the Moreau Seminary has ties to theologian Frederick Buechner. While not Catholic, Buechner has praised writers from Notre Dame and Moreau Seminary created a Buechner Prize for Preaching. The College of Engineering was established in 1920, however, early courses in civil and mechanical engineering were a part of the College of Science since the 1870s. Today the college, housed in the Fitzpatrick, Cushing, and Stinson-Remick Halls of Engineering, includes five departments of study – aerospace and mechanical engineering, chemical and biomolecular engineering, civil engineering and geological sciences, computer science and engineering, and electrical engineering – with eight B.S. degrees offered. Additionally, the college offers five-year dual degree programs with the Colleges of Arts and Letters and of Business awarding additional B.A. and Master of Business Administration (MBA) degrees, respectively. All of Notre Dame\\'s undergraduate students are a part of one of the five undergraduate colleges at the school or are in the First Year of Studies program. The First Year of Studies program was established in 1962 to guide incoming freshmen in their first year at the school before they have declared a major. Each student is given an academic advisor from the program who helps them to choose classes that give them exposure to any major in which they are interested. The program also includes a Learning Resource Center which provides time management, collaborative learning, and subject tutoring. This program has been recognized previously, by U.S. News & World Report, as outstanding.',\n",
              " 'qas': [{'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
              "   'answers': {'text': ['Saint Bernadette Soubirous'],\n",
              "    'answer_start': [515],\n",
              "    'answer_start_full_para': [515]},\n",
              "   'context_counts': 1,\n",
              "   'current_context_len': 695},\n",
              "  {'question': 'What is in front of the Notre Dame Main Building?',\n",
              "   'answers': {'text': ['a copper statue of Christ'],\n",
              "    'answer_start': [188],\n",
              "    'answer_start_full_para': [188]},\n",
              "   'context_counts': 1,\n",
              "   'current_context_len': 695},\n",
              "  {'question': 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?',\n",
              "   'answers': {'text': ['the Main Building'],\n",
              "    'answer_start': [279],\n",
              "    'answer_start_full_para': [279]},\n",
              "   'context_counts': 1,\n",
              "   'current_context_len': 695},\n",
              "  {'question': 'What is the Grotto at Notre Dame?',\n",
              "   'answers': {'text': ['a Marian place of prayer and reflection'],\n",
              "    'answer_start': [381],\n",
              "    'answer_start_full_para': [381]},\n",
              "   'context_counts': 1,\n",
              "   'current_context_len': 695},\n",
              "  {'question': 'What sits on top of the Main Building at Notre Dame?',\n",
              "   'answers': {'text': ['a golden statue of the Virgin Mary'],\n",
              "    'answer_start': [92],\n",
              "    'answer_start_full_para': [92]},\n",
              "   'context_counts': 1,\n",
              "   'current_context_len': 695},\n",
              "  {'question': 'When did the Scholastic Magazine of Notre dame begin publishing?',\n",
              "   'answers': {'text': ['September 1876'],\n",
              "    'answer_start': [248],\n",
              "    'answer_start_full_para': [944]},\n",
              "   'context_counts': 2,\n",
              "   'current_context_len': 2100},\n",
              "  {'question': \"How often is Notre Dame's the Juggler published?\",\n",
              "   'answers': {'text': ['twice'],\n",
              "    'answer_start': [441],\n",
              "    'answer_start_full_para': [1137]},\n",
              "   'context_counts': 2,\n",
              "   'current_context_len': 2100},\n",
              "  {'question': 'What is the daily student paper at Notre Dame called?',\n",
              "   'answers': {'text': ['The Observer'],\n",
              "    'answer_start': [598],\n",
              "    'answer_start_full_para': [1294]},\n",
              "   'context_counts': 2,\n",
              "   'current_context_len': 2100},\n",
              "  {'question': 'How many student news papers are found at Notre Dame?',\n",
              "   'answers': {'text': ['three'],\n",
              "    'answer_start': [126],\n",
              "    'answer_start_full_para': [822]},\n",
              "   'context_counts': 2,\n",
              "   'current_context_len': 2100},\n",
              "  {'question': 'In what year did the student paper Common Sense begin publication at Notre Dame?',\n",
              "   'answers': {'text': ['1987'],\n",
              "    'answer_start': [908],\n",
              "    'answer_start_full_para': [1604]},\n",
              "   'context_counts': 2,\n",
              "   'current_context_len': 2100},\n",
              "  {'question': 'Where is the headquarters of the Congregation of the Holy Cross?',\n",
              "   'answers': {'text': ['Rome'],\n",
              "    'answer_start': [119],\n",
              "    'answer_start_full_para': [2221]},\n",
              "   'context_counts': 3,\n",
              "   'current_context_len': 2804},\n",
              "  {'question': 'What is the primary seminary of the Congregation of the Holy Cross?',\n",
              "   'answers': {'text': ['Moreau Seminary'],\n",
              "    'answer_start': [145],\n",
              "    'answer_start_full_para': [2247]},\n",
              "   'context_counts': 3,\n",
              "   'current_context_len': 2804},\n",
              "  {'question': 'What is the oldest structure at Notre Dame?',\n",
              "   'answers': {'text': ['Old College'],\n",
              "    'answer_start': [234],\n",
              "    'answer_start_full_para': [2336]},\n",
              "   'context_counts': 3,\n",
              "   'current_context_len': 2804},\n",
              "  {'question': 'What individuals live at Fatima House at Notre Dame?',\n",
              "   'answers': {'text': ['Retired priests and brothers'],\n",
              "    'answer_start': [356],\n",
              "    'answer_start_full_para': [2458]},\n",
              "   'context_counts': 3,\n",
              "   'current_context_len': 2804},\n",
              "  {'question': 'Which prize did Frederick Buechner create?',\n",
              "   'answers': {'text': ['Buechner Prize for Preaching'],\n",
              "    'answer_start': [675],\n",
              "    'answer_start_full_para': [2777]},\n",
              "   'context_counts': 3,\n",
              "   'current_context_len': 2804},\n",
              "  {'question': 'How many BS level degrees are offered in the College of Engineering at Notre Dame?',\n",
              "   'answers': {'text': ['eight'],\n",
              "    'answer_start': [487],\n",
              "    'answer_start_full_para': [3294]},\n",
              "   'context_counts': 4,\n",
              "   'current_context_len': 3528},\n",
              "  {'question': 'In what year was the College of Engineering at Notre Dame formed?',\n",
              "   'answers': {'text': ['1920'],\n",
              "    'answer_start': [46],\n",
              "    'answer_start_full_para': [2853]},\n",
              "   'context_counts': 4,\n",
              "   'current_context_len': 3528},\n",
              "  {'question': 'Before the creation of the College of Engineering similar studies were carried out at which Notre Dame college?',\n",
              "   'answers': {'text': ['the College of Science'],\n",
              "    'answer_start': [126],\n",
              "    'answer_start_full_para': [2933]},\n",
              "   'context_counts': 4,\n",
              "   'current_context_len': 3528},\n",
              "  {'question': 'How many departments are within the Stinson-Remick Hall of Engineering?',\n",
              "   'answers': {'text': ['five'],\n",
              "    'answer_start': [271],\n",
              "    'answer_start_full_para': [3078]},\n",
              "   'context_counts': 4,\n",
              "   'current_context_len': 3528},\n",
              "  {'question': 'The College of Science began to offer civil engineering courses beginning at what time at Notre Dame?',\n",
              "   'answers': {'text': ['the 1870s'],\n",
              "    'answer_start': [155],\n",
              "    'answer_start_full_para': [2962]},\n",
              "   'context_counts': 4,\n",
              "   'current_context_len': 3528},\n",
              "  {'question': 'What entity provides help with the management of time for new students at Notre Dame?',\n",
              "   'answers': {'text': ['Learning Resource Center'],\n",
              "    'answer_start': [496],\n",
              "    'answer_start_full_para': [4028]},\n",
              "   'context_counts': 5,\n",
              "   'current_context_len': 4216}],\n",
              " 'sentences': {'0': {'start_index': 0, 'end_index': 53},\n",
              "  '1': {'start_index': 54, 'end_index': 127},\n",
              "  '2': {'start_index': 128, 'end_index': 270},\n",
              "  '3': {'start_index': 271, 'end_index': 333},\n",
              "  '4': {'start_index': 334, 'end_index': 421},\n",
              "  '5': {'start_index': 422, 'end_index': 550},\n",
              "  '6': {'start_index': 551, 'end_index': 695},\n",
              "  '7': {'start_index': 696, 'end_index': 784},\n",
              "  '8': {'start_index': 785, 'end_index': 912},\n",
              "  '9': {'start_index': 913, 'end_index': 1091},\n",
              "  '10': {'start_index': 1092, 'end_index': 1196},\n",
              "  '11': {'start_index': 1197, 'end_index': 1237},\n",
              "  '12': {'start_index': 1238, 'end_index': 1441},\n",
              "  '13': {'start_index': 1442, 'end_index': 1600},\n",
              "  '14': {'start_index': 1601, 'end_index': 1739},\n",
              "  '15': {'start_index': 1740, 'end_index': 1882},\n",
              "  '16': {'start_index': 1883, 'end_index': 1987},\n",
              "  '17': {'start_index': 1988, 'end_index': 2101},\n",
              "  '18': {'start_index': 2102, 'end_index': 2227},\n",
              "  '19': {'start_index': 2228, 'end_index': 2335},\n",
              "  '20': {'start_index': 2336, 'end_index': 2457},\n",
              "  '21': {'start_index': 2458, 'end_index': 2595},\n",
              "  '22': {'start_index': 2596, 'end_index': 2681},\n",
              "  '23': {'start_index': 2682, 'end_index': 2806},\n",
              "  '24': {'start_index': 2807, 'end_index': 2972},\n",
              "  '25': {'start_index': 2973, 'end_index': 3304},\n",
              "  '26': {'start_index': 3305, 'end_index': 3321},\n",
              "  '27': {'start_index': 3322, 'end_index': 3464},\n",
              "  '28': {'start_index': 3465, 'end_index': 3531},\n",
              "  '29': {'start_index': 3532, 'end_index': 3686},\n",
              "  '30': {'start_index': 3687, 'end_index': 3840},\n",
              "  '31': {'start_index': 3841, 'end_index': 3999},\n",
              "  '32': {'start_index': 4000, 'end_index': 4130},\n",
              "  '33': {'start_index': 4131, 'end_index': 4220}}}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2neLRNpPERwy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "94d9584b118b43e880c59b0ee3226d29",
            "afe49945cf554eb3a17b9d916100dfd0",
            "2b26a675be0d4715960d66bacf9e53f5",
            "29fc880a24164c33be6a003e9dcbfd98",
            "7eb144d07cd44fd1aa398953f79fcbfe",
            "8be62225d88c4279967d6450ab2c927c",
            "2200e58948e247dcb9bfbde51d4b333d",
            "1f1ea1bb0e2e410685af419068ccd183",
            "4e2a33644e524b3fb3ed504c24125c47",
            "8304d959e0c34d1eae63e34f8f742735",
            "d116ee67b0114c4c8f48d56139afa805",
            "05bff5d46fbf4fa5938f98746eb7a9bd",
            "b0c6c19154ba41f983bd6fc73adeb441",
            "cb2fab4d8f6b4d68a46b840613ffcc1d",
            "f11d06a2b44045368d039884b9b981ff",
            "57be918d229f44bf849dd322abf2e905",
            "8314e3d5fed243b98059286512220b41",
            "3f37ab300c104d3dae816df7c1ce7674",
            "2fb601723cae4c1c8ec79ded7fa21a24",
            "0e8d2a70f2114b8c8e6c5f93508ff89f",
            "41fecc42a52347dfad110764b208025d",
            "f6d3fbfed9df43878d5c8ecda6d8e5e6",
            "36db0fd0b52e43999c71cff33546b5bc",
            "b6e83119dc984cc48d4e02fd0846dc71",
            "f76416c2e2d4412e97555a25fc827f52",
            "22ef8269e9e24ec39aa86b36aebd484f",
            "9c2b6894f2784cdebfdb75a2081eab15",
            "1460a724714647728da30d18c16e7d70",
            "772b33e902ce4f9989744a8f0dec9a52",
            "efb5655fa623444ea2b42d6578de0210",
            "a02a9d5ea2144914ad7fdfc8f73cbbff",
            "c0bf774aec714c1b81bec124a5755466",
            "6f00b3f60b1c41dc81eeaff0f2d9de86",
            "0be33c32a2f94f60889a499ff1db5b6e",
            "f6b62398b4ca46109cc960a2017ab43c",
            "6905298e19f7493491161f5d7bb3cda6",
            "8fd6543fe3804e6395ddad7507e33c51",
            "d3b2e571942f4fa2af653b1c015a2521",
            "547465d53e4248a39c3070564342ae42",
            "df6c249fe14949178974d96a90c73919",
            "84772da02d374caeab2a880d7e5c096c",
            "1e9fbe81241f4f1390bd6c7ea74e0592",
            "63af5b17679a4c7d9b6ab48277e1c084",
            "4f24762c40f540a8a6c4770489455703"
          ]
        },
        "outputId": "79ae1ebb-b99a-4410-fa94-491ab8ac3530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94d9584b118b43e880c59b0ee3226d29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05bff5d46fbf4fa5938f98746eb7a9bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36db0fd0b52e43999c71cff33546b5bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0be33c32a2f94f60889a499ff1db5b6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10014,\n",
              " dict_keys(['text', 'title', 'sentence_end', 'question', 'answer_index']))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "def find_sentence_by_index(data, index):\n",
        "    for key, value in data.items():\n",
        "        if value['start_index'] <= index <= value['end_index']:\n",
        "            return key, value[\"end_index\"]\n",
        "    return None\n",
        "\n",
        "\n",
        "def flattern_data(data_raw):\n",
        "  data_ready_flat = []\n",
        "  for doc_data in data_ready:\n",
        "      for question_data in doc_data.values():\n",
        "          data_ready_flat.append(question_data)\n",
        "  return data_ready_flat\n",
        "\n",
        "\n",
        "def make_model_ready_data(data):\n",
        "  tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
        "  data_ready = []\n",
        "\n",
        "  for data_index, data_temp in enumerate(data):\n",
        "      dict_d = {}\n",
        "      # For text and sentence_end\n",
        "      para = data[data_index][\"context\"]\n",
        "      sentences = []\n",
        "      sent_end_tokens = []\n",
        "      # Get all the sentences based on indexes\n",
        "      for sen_num, sen_idx in data[data_index][\"sentences\"].items():\n",
        "          sentence_text = para[sen_idx[\"start_index\"]: sen_idx[\"end_index\"]]\n",
        "          sentences.append(sentence_text)\n",
        "\n",
        "      text_tokens = [tokenizer(sen, return_tensors=\"pt\")[\"input_ids\"] for sen in sentences]\n",
        "      for tensor in text_tokens:\n",
        "          new_list_single = [0] * len(tensor[0])\n",
        "          new_list_single[-1] = 1  # Set last element to 1\n",
        "          sent_end_tokens.append(new_list_single)\n",
        "\n",
        "\n",
        "      # For answers and answer_sentences\n",
        "      for i, qas in enumerate(data[data_index][\"qas\"]):\n",
        "          question = qas[\"question\"]\n",
        "          q_tokens = tokenizer(question, return_tensors=\"pt\")[\"input_ids\"]\n",
        "          answer_index = qas[\"answers\"][\"answer_start_full_para\"][0]\n",
        "          answer_sent_index, answer_end_index = find_sentence_by_index(data[data_index][\"sentences\"], answer_index)\n",
        "          dict_d[i] = {\"text\": text_tokens, \"title\": data_temp[\"title\"],\"sentence_end\": sent_end_tokens,\n",
        "                      \"question\": {\"raw\":question, \"question_token\": q_tokens} ,\n",
        "                      \"answer_index\": {\"answer_sent_index\": int(answer_sent_index), \"answer_end_index\": answer_end_index}}\n",
        "      data_ready.append(dict_d)\n",
        "  return data_ready\n",
        "\n",
        "\n",
        "# Functions for Formatting the dataset for model input.\n",
        "data_ready = make_model_ready_data(data)\n",
        "data_ready_flat = flattern_data(data_ready)\n",
        "len(data_ready_flat), data_ready_flat[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lIa5avMF6ZoG"
      },
      "outputs": [],
      "source": [
        "# Dataset Builders\n",
        "def data_collater(batch):\n",
        "    def flatten_sentence_ends(sentence_ends):\n",
        "        return torch.tensor([item for sublist in sentence_ends for item in sublist])\n",
        "    batch_sentence_ends = [flatten_sentence_ends(d['sentence_end']) for d in batch]\n",
        "\n",
        "    def flatten_text(text_tokens):\n",
        "      return torch.cat(text_tokens, axis=-1).flatten()\n",
        "    batch_text = [flatten_text(d['text']) for d in batch]\n",
        "\n",
        "    batch_questions = [d['question']['raw'] for d in batch]\n",
        "\n",
        "    def get_answer_idx(sentence_ends_flat, answer_sent_index):\n",
        "        sentence_ends_flat_idx = sentence_ends_flat.nonzero()\n",
        "        answer_idx = sentence_ends_flat_idx[answer_sent_index]\n",
        "        return answer_idx\n",
        "\n",
        "    batch_answer_idx = [get_answer_idx(sent_ends, d['answer_index']['answer_sent_index'])\n",
        "                        for sent_ends, d in zip(batch_sentence_ends, batch)]\n",
        "\n",
        "    batch_title = [t[\"title\"] for t in batch]\n",
        "    return batch_questions, batch_sentence_ends, batch_text, batch_title, batch_answer_idx\n",
        "\n",
        "\n",
        "class ListDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4-JEUVkLlz3"
      },
      "source": [
        "### Get Wiki Embedding data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the subset of embeddings from Cohere/wikipedia-22–12-en-embeddings  ([link](https://huggingface.co/datasets/Cohere/wikipedia-22-12-en-embeddings)) as distraction documents for the retrieval process. We mapped `title` as a key while outputing the dictionaly which saved into the pickle file formats."
      ],
      "metadata": {
        "id": "jB6kZLmfuYy8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x4krH-TDLk3H"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Research: Elan<>Krupa/wikipedia-22-12-en-embeddings_squad_doc_subset_4000000.pkl', 'rb') as f:\n",
        "    wiki_docs = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zWC3eDjZPN8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c86b1b-b652-45d5-93cb-60aa55f8ff3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([99, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# convert the docs to single matrices for each title\n",
        "# dict(array([num docs for title x 768])) where each row corresponds to the index in wiki_docs for that title\n",
        "\n",
        "doc_embs = {}\n",
        "for title, docs in wiki_docs.items():\n",
        "    embs = []\n",
        "    for doc in docs:\n",
        "        embs.append(doc['emb'])\n",
        "    doc_embs[title] = torch.from_numpy(np.array(embs))\n",
        "doc_embs['University of Notre Dame'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ayKuCay6CCq"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "r32onN15cNdp"
      },
      "outputs": [],
      "source": [
        "def sample_until_answer_divergence(sentence_ends, text, answer_idx, model, greedy=True):\n",
        "    current_idx = 0\n",
        "    sample1_single, sample2_single = [], []\n",
        "    divergence = None\n",
        "    while current_idx < len(text):\n",
        "        text_input = text[current_idx:current_idx+400]\n",
        "        sentence_ends_input = sentence_ends[current_idx:current_idx+400] # [0,0,0,1,0,0,0,1,0,0,0,1] ...\n",
        "        sentence_ends_idx = torch.nonzero(sentence_ends_input).squeeze(-1) # [3, 7, 11] ... [489, 555, 600]....\n",
        "        logits = model(text_input.reshape(1,-1), [sentence_ends_idx])[0]\n",
        "\n",
        "        probs = torch.nn.functional.softmax(logits, dim=-1) # gives logits for chunking at the sentence_ends_idx (same shape as sentence_ends_idx)\n",
        "        if len(probs) < 2:\n",
        "            return [], [], None\n",
        "\n",
        "        if greedy:\n",
        "            x2, x2_alt = torch.multinomial(probs, 2, replacement=False)\n",
        "            x1 = torch.argmax(probs, dim=-1)\n",
        "        else:\n",
        "            x1, x2 = torch.multinomial(probs, 2, replacement=False)\n",
        "        if x2 == x1:\n",
        "            x2 = x2_alt\n",
        "        chunk_end = current_idx + sentence_ends_idx[x1] + 1\n",
        "        if chunk_end < answer_idx: # chunks before answer index.\n",
        "            sample1_single.append(chunk_end)\n",
        "            sample2_single.append(chunk_end)\n",
        "\n",
        "            current_idx = chunk_end\n",
        "        else: # i.e. chunks after answer index\n",
        "            sample1_single.append(chunk_end) # sample1_single with having chunk_end higher then answer index\n",
        "            chunk_end2 = current_idx + sentence_ends_idx[x2] + 1 # sample2_single\n",
        "            sample2_single.append(chunk_end2)\n",
        "            divergence = (text_input.reshape(1,-1), sentence_ends_idx, x1, x2)\n",
        "            break # reached to chunk having answer index so break it\n",
        "    return sample1_single, sample2_single, divergence\n",
        "\n",
        "\n",
        "def sample_chunking_with_divergence(sentence_ends, text, answer_idx, model, device):\n",
        "    with torch.no_grad():\n",
        "        divergence = None\n",
        "        count = 0\n",
        "        while divergence is None:\n",
        "            sample1_single, sample2_single, divergence = sample_until_answer_divergence(sentence_ends, text, answer_idx, model, greedy=(count==0))\n",
        "\n",
        "            count += 1\n",
        "            if count > 50:\n",
        "                print(f'Failed to sample from {sentence_ends}, {text}, {answer_idx}')\n",
        "                return\n",
        "\n",
        "\n",
        "        # complete sample1_single\n",
        "        current_idx = int(sample1_single[-1])\n",
        "        while current_idx < len(text):\n",
        "            text_input = text[current_idx:current_idx+400]\n",
        "            sentence_ends_input = sentence_ends[current_idx:current_idx+400] # [0,0,0,1,0,0,0,1,0,0,0,1].....\n",
        "            sentence_ends_idx = torch.nonzero(sentence_ends_input).squeeze(-1)\n",
        "            logits = model(text_input.reshape(1,-1), [sentence_ends_idx])[0]\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            x = torch.argmax(probs, dim=-1)\n",
        "            # x = torch.multinomial(probs, 1).squeeze()\n",
        "            chunk_end = current_idx + sentence_ends_idx[x] + 1\n",
        "            sample1_single.append(chunk_end)\n",
        "            current_idx = chunk_end\n",
        "\n",
        "\n",
        "        # complete sample2_single\n",
        "        current_idx = int(sample2_single[-1])\n",
        "        while current_idx < len(text):\n",
        "            text_input = text[current_idx:current_idx+400]\n",
        "            sentence_ends_input = sentence_ends[current_idx:current_idx+400] # [0,0,0,1,0,0,0,1,0,0,0,1]......\n",
        "            sentence_ends_idx = torch.nonzero(sentence_ends_input).squeeze(-1)\n",
        "            logits = model(text_input.reshape(1,-1), [sentence_ends_idx])[0]\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            x = torch.argmax(probs, dim=-1)\n",
        "            # x = torch.multinomial(probs, 1).squeeze()\n",
        "            chunk_end = current_idx + sentence_ends_idx[x] + 1\n",
        "            sample2_single.append(chunk_end)\n",
        "            current_idx = chunk_end\n",
        "\n",
        "    return sample1_single, sample2_single, divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H73QH8iqyatr"
      },
      "source": [
        "### Cohere embedding creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vNjVhjU1yhcq"
      },
      "outputs": [],
      "source": [
        "co = cohere.Client(f\"{userdata.get('CO_API_PAID')}\")\n",
        "embedding_model_id = \"multilingual-22-12\"\n",
        "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IW59EqbOyoET"
      },
      "outputs": [],
      "source": [
        "def get_cohere_emb(text_list):\n",
        "    emb = co.embed(texts= text_list, model=embedding_model_id)\n",
        "    return emb\n",
        "\n",
        "\n",
        "def get_samples_emb(samples, title, text, answer_idx):\n",
        "    org_text = []\n",
        "    start_index = torch.tensor(0, device=answer_idx.device)\n",
        "    result_index = None\n",
        "    # Get raw text\n",
        "    for sample_index, sample in enumerate(samples):\n",
        "        chunk_token = text[start_index: sample]\n",
        "        org_chunk_text = tokenizer.decode(chunk_token)\n",
        "\n",
        "        # print(len(chunk_token), start_index, sample)\n",
        "        org_chunk_text = title + \" \" + org_chunk_text # Add title to org_chunk_text.\n",
        "        org_text.append(org_chunk_text)\n",
        "\n",
        "        if start_index < answer_idx < sample: # Assign the answer index.\n",
        "          result_index = sample_index\n",
        "\n",
        "        start_index = sample\n",
        "\n",
        "    # Get embeddings.\n",
        "    chunk_emb = get_cohere_emb(org_text)\n",
        "    return org_text, chunk_emb, result_index\n",
        "\n",
        "def prep_samples_for_emb(samples, title, text, answer_idx):\n",
        "    org_text = []\n",
        "    start_index = torch.tensor(0, device=answer_idx.device)\n",
        "    result_index = None\n",
        "    # Get raw text\n",
        "    for sample_index, sample in enumerate(samples):\n",
        "        chunk_token = text[start_index: sample]\n",
        "        org_chunk_text = tokenizer.decode(chunk_token)\n",
        "\n",
        "        # print(len(chunk_token), start_index, sample)\n",
        "        org_chunk_text = title + \" \" + org_chunk_text # add title to org_chunk_text.\n",
        "        org_text.append(org_chunk_text)\n",
        "\n",
        "        if start_index < answer_idx < sample: # Assign the answer index\n",
        "          result_index = sample_index\n",
        "\n",
        "        start_index = sample\n",
        "\n",
        "    return org_text, result_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lgku7M17nsSo"
      },
      "outputs": [],
      "source": [
        "# Functions to get embedding for the samples.\n",
        "\n",
        "def get_random_wiki(doc_embs, wiki_counts):\n",
        "  keys_list = list(doc_embs.keys())\n",
        "  random_keys = random.sample(keys_list, wiki_counts)\n",
        "  # Access the values using the random keys.\n",
        "  wiki_emb_list = []\n",
        "  for key in random_keys:\n",
        "    value = doc_embs[key]\n",
        "    value1 = random.choice(value)\n",
        "    wiki_emb_list.append(value1)\n",
        "  return wiki_emb_list\n",
        "\n",
        "\n",
        "def add_wiki_sample_emb(sample_emb, doc_embs, wiki_counts=7):\n",
        "  mapper = []\n",
        "  sample_embedding = torch.from_numpy(np.array(sample_emb))\n",
        "  mapper[0:len(sample_embedding)] = [\"Sample\"]* len(sample_embedding)\n",
        "  wiki_embedding = get_random_wiki(doc_embs, wiki_counts)\n",
        "  wiki_embedding = torch.from_numpy(np.array(wiki_embedding))\n",
        "\n",
        "  mapper[len(sample_embedding):len(wiki_embedding)] = [\"Wiki\"]* len(wiki_embedding)\n",
        "\n",
        "  # Combine both the embeddings.\n",
        "  all_embedding = torch.cat((sample_embedding, wiki_embedding), dim=0)\n",
        "  return all_embedding, mapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CodfCqsy7Iqq"
      },
      "source": [
        "## Retrieval and get the raw chunk data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "mR9xE4iqB2_E"
      },
      "outputs": [],
      "source": [
        "# get all chunks up to and including answer chunk\n",
        "# tokenize and aggregate to get number of tokens before winning chunk.\n",
        "\n",
        "def get_chunk_tokenize(top_k, mapper, result_index, sample_raw, wiki_docs, title):\n",
        "    count = 0\n",
        "    chunk_list = []\n",
        "    for index in top_k:\n",
        "        index = int(index)\n",
        "        map_location = mapper[index]\n",
        "        if map_location == \"Sample\":\n",
        "            chunk_list.append(sample_raw[index])\n",
        "        elif map_location == \"Wiki\":\n",
        "            # get the wiki_raw data\n",
        "            wiki_index = index - mapper.index(\"Wiki\")\n",
        "            wiki_raw = wiki_docs[title][wiki_index][\"text\"]\n",
        "\n",
        "            # assert is just to check to make sure we have got the correct wiki_raw\n",
        "            # assert torch.all(torch.from_numpy(wiki_docs[title][wiki_index][\"emb\"]) == doc_embeddings[check_index])\n",
        "            chunk_list.append(wiki_raw)\n",
        "\n",
        "        if index == result_index:\n",
        "            # got the chunk having the answer.\n",
        "            break\n",
        "\n",
        "    context_text_until_result = '\\n'.join(chunk_list)\n",
        "    chunk_tokens = tokenizer(context_text_until_result, return_tensors=\"pt\")[\"input_ids\"][0]\n",
        "    return chunk_list, chunk_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP_dOHZs60j8"
      },
      "source": [
        "## Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "O3a48uJCxlx8"
      },
      "outputs": [],
      "source": [
        "# After getting preference data, re run point where preference data diverges and train with ranking objective.\n",
        "\n",
        "def train_pref(divergences, text_mask, preferences, model, loss_fn, opt):\n",
        "\n",
        "    opt.zero_grad()\n",
        "    logits_list = model(divergences[0], divergences[1], attention_mask=text_mask) # list of distributions\n",
        "    distributions = [torch.nn.functional.softmax(l, dim=-1) for l in logits_list]\n",
        "\n",
        "    x_samples = torch.stack([divergences[2], divergences[3]], dim=-1) # x1 and x2 from the sampled output\n",
        "    x_samples = x_samples.to(logits_list[0].device)\n",
        "    logits_stacked, logits_mask = padded_stack(logits_list)\n",
        "    assert torch.all(torch.gather(logits_mask, -1, x_samples))\n",
        "    logits_sampled = torch.gather(logits_stacked, -1, x_samples)\n",
        "    norm_entropies = torch.tensor([Categorical(probs = dist).entropy() / torch.log(torch.tensor(dist.shape[0])) for dist in distributions])\n",
        "    average_entropy = norm_entropies.mean()\n",
        "    # print(\"entropy\", entropy)\n",
        "    # x_probs = probs[x_samples]\n",
        "    # probs_winner = x_probs[:, winner]\n",
        "    # probs_loser = x_probs[:, loser]\n",
        "\n",
        "\n",
        "    # preferences = 1-(preferences * 2) # convert 0->1 1->-1 # MarginRankingLoss format\n",
        "    # loss = loss_fn(logits_sampled[:,0], logits_sampled[:,1], preferences)\n",
        "    loss = loss_fn(logits_sampled, preferences)\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    return loss, average_entropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MyTblsagrj7A"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, rundir, epoch, step):\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'step': step\n",
        "    }, os.path.join(rundir, f'checkpoint_{epoch}_{step:0{6}}.pth'))\n",
        "\n",
        "def load_checkpoint(model, optimizer, rundir, step):\n",
        "    # Load model checkpoint and optimizer checkpoint\n",
        "    loadfile = os.path.join(rundir, f'checkpoint_{step:0{6}}')\n",
        "    loaded_checkpoint = torch.load(loadfile)\n",
        "    model.load_state_dict(loaded_checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(loaded_checkpoint['optimizer_state_dict'])\n",
        "    print(f'Checkpoint loaded from {loadfile}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7dyTxzfHW3j0"
      },
      "outputs": [],
      "source": [
        "def padded_stack(sequences):\n",
        "    # Pad sequences to the maximum length\n",
        "    padded_sequences = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=-1)\n",
        "\n",
        "    # Create a binary mask indicating valid elements\n",
        "    mask = (padded_sequences != -1)\n",
        "    padded_sequences[padded_sequences == -1] = 0\n",
        "\n",
        "    return padded_sequences, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "n8U40e55fbw_"
      },
      "outputs": [],
      "source": [
        "class ChunkerModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = T5EncoderModel.from_pretrained('google/flan-t5-base')\n",
        "        self.classifier = torch.nn.Linear(768,1)\n",
        "\n",
        "    def forward(self, input_ids, sentence_ends_idx, attention_mask=None):\n",
        "        \"\"\"\n",
        "            input_ids: B x seq_length(400)\n",
        "            sentence_dneds_idx: List[Tensor], B tensors of shape #sentence_ends\n",
        "        \"\"\"\n",
        "\n",
        "        embeds = self.encoder(input_ids, attention_mask=attention_mask)['last_hidden_state']\n",
        "\n",
        "        sentence_ends_embeds = [emb[sentence_ends_idx[i]] for i, emb in enumerate(embeds)]\n",
        "        # sentence_ends_embeds = embeds[0][sentence_ends_idx]\n",
        "        preds = [self.classifier(sentence_ends_emb).squeeze(-1) for sentence_ends_emb in sentence_ends_embeds]\n",
        "        # try:\n",
        "        #   preds = torch.tensor(preds)\n",
        "        # except ValueError as e:\n",
        "        #   # for train pref\n",
        "        #   preds = torch.stack(preds)\n",
        "        return preds\n",
        "\n",
        "\n",
        "def set_seeds(seed: int=1234):\n",
        "    \"\"\"Sets random sets for torch operations.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed to set. Defaults to 42.\n",
        "    \"\"\"\n",
        "    # Set the seed for general torch operations\n",
        "    torch.manual_seed(seed)\n",
        "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "\n",
        "PREFERENCE_DATA_DIR = '/content/drive/MyDrive/Research: Elan<>Krupa/preference_data'\n",
        "def save_preference_data(chunk, chunk_count):\n",
        "    current = chunk_count\n",
        "    filepath = os.path.join(PREFERENCE_DATA_DIR, f'{current:0{6}}.pth')\n",
        "    # print(f'saving to {filepath}')\n",
        "    torch.save(chunk, filepath)\n",
        "\n",
        "# def get_num_chunks_cached():\n",
        "#     chunkfilelist = os.listdir(PREFERENCE_DATA_DIR)\n",
        "#     chunklist = [int(os.path.splitext(f)[0]) for f in chunkfilelist if os.path.splitext(f)[1] == '.pth']\n",
        "#     if chunklist:\n",
        "#         current = max(chunklist) + 1\n",
        "#     else:\n",
        "#         current = 0\n",
        "#     return current\n",
        "\n",
        "def load_preference_data(current):\n",
        "    filepath = os.path.join(PREFERENCE_DATA_DIR, f'{current:0{6}}.pth')\n",
        "    chunk = torch.load(filepath)\n",
        "    return chunk\n",
        "\n",
        "\n",
        "def main():\n",
        "    RUNDIR = '/content/drive/MyDrive/Research: Elan<>Krupa/run_testing'\n",
        "    LR = 0.01\n",
        "    BATCH_SIZE = 12 #24\n",
        "    EPOCHS = 1\n",
        "    hparams = {\n",
        "        'lr': LR,\n",
        "        'batch': BATCH_SIZE,\n",
        "        'epochs': EPOCHS\n",
        "    }\n",
        "    set_seeds(1234)\n",
        "\n",
        "    wandb.init(\n",
        "    # set the wandb project where this run will be logged\n",
        "    project=\"smart_chunker_8_25\",\n",
        "    # track hyperparameters and run metadata\n",
        "    config=hparams\n",
        "    )\n",
        "\n",
        "    LOSS_WINDOW = 20\n",
        "    CACHE_PREFERENCE_DATA = False\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    dataset = ListDataset(data_ready_flat)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data_collater)\n",
        "\n",
        "    model = ChunkerModel()\n",
        "    device = \"cuda\"\n",
        "    model.to(device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    # loss_fn = torch.nn.MarginRankingLoss(margin=1.0)\n",
        "\n",
        "    chunk_count = -1 # start at -1 so that it immediately increments to zero\n",
        "\n",
        "    BATCH = None\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        for i, batch in tqdm.tqdm(enumerate(dataloader), total=len(dataloader)):\n",
        "            # if BATCH is None:\n",
        "            #     BATCH = batch\n",
        "            # else:\n",
        "            #     batch = BATCH\n",
        "            chunking_samples = []\n",
        "            for question, sentence_ends, text, title, answer_idx in zip(*batch):\n",
        "                chunk_count += 1\n",
        "                if CACHE_PREFERENCE_DATA:\n",
        "                    try:\n",
        "                        chunk_sample = load_preference_data(chunk_count)\n",
        "                        chunking_samples.append(chunk_sample)\n",
        "                        continue\n",
        "                    except FileNotFoundError:\n",
        "                        pass\n",
        "\n",
        "                if title.replace(\"_\", \" \") not in doc_embs: # Extra step for missing docs.\n",
        "                    continue\n",
        "                sentence_ends, text, answer_idx = sentence_ends.to(device), text.to(device), answer_idx.to(device)\n",
        "                sample1_single, sample2_single, divergence = sample_chunking_with_divergence(sentence_ends, text, answer_idx, model, device)\n",
        "\n",
        "\n",
        "                chunk_sample = {\"title\": title,\n",
        "                                        \"text\":  text,\n",
        "                                        \"sample1\": sample1_single,\n",
        "                                        \"sample2\": sample2_single,\n",
        "                                        \"answer_idx\": answer_idx,\n",
        "                                        \"divergence\": divergence,\n",
        "                                        \"question_raw\": question}\n",
        "\n",
        "                text_sample = chunk_sample[\"text\"]\n",
        "                title_sample = chunk_sample[\"title\"]\n",
        "                title_sample = title_sample.replace(\"_\", \" \") # Extra step to get match for wiki data title\n",
        "                sample1_sample = chunk_sample[\"sample1\"]\n",
        "                sample2_sample = chunk_sample[\"sample2\"]\n",
        "                answer_idx_single  = chunk_sample[\"answer_idx\"]\n",
        "                divergence_sample = chunk_sample[\"divergence\"]\n",
        "                question_sample= chunk_sample[\"question_raw\"]\n",
        "\n",
        "                sample1_raw, result_index1 = prep_samples_for_emb(sample1_sample, title_sample,  text_sample, answer_idx_single)\n",
        "                sample2_raw, result_index2 = prep_samples_for_emb(sample2_sample, title_sample,  text_sample, answer_idx_single)\n",
        "                to_emb = sample1_raw + sample2_raw + [title_sample + \" \"+ question_sample]\n",
        "                embs = get_cohere_emb(to_emb)\n",
        "                question_emb = embs.embeddings[-1:]\n",
        "                sample1_emb = embs.embeddings[0:len(sample1_raw)]\n",
        "                sample2_emb = embs.embeddings[len(sample1_raw):-1]\n",
        "                assert len(sample2_emb) == len(sample2_raw)\n",
        "\n",
        "                # wiki_emb = doc_embs[title_sample]\n",
        "                sample1_all_emb, mapper1 = add_wiki_sample_emb(sample1_emb, doc_embs)\n",
        "                sample2_all_emb, mapper2 = add_wiki_sample_emb(sample2_emb, doc_embs)\n",
        "                q_embedding = torch.tensor(np.array(question_emb))\n",
        "\n",
        "                # Compute dot score between query embedding and document embeddings.\n",
        "                with torch.no_grad():\n",
        "                    dot_scores1 = torch.mm(q_embedding, sample1_all_emb.transpose(0,1))\n",
        "                    top_k1 = torch.topk(dot_scores1, k=min(10, dot_scores1.shape[-1])).indices.flatten()\n",
        "                    dot_scores2 = torch.mm(q_embedding, sample2_all_emb.transpose(0,1))\n",
        "                    top_k2 = torch.topk(dot_scores2, k=min(10, dot_scores2.shape[-1])).indices.flatten()\n",
        "\n",
        "                    # identify the number of tokens until correct document (inclusive).\n",
        "                    chunk_list1, chunk_tokens1 = get_chunk_tokenize(top_k1, mapper1, result_index1, sample1_raw, wiki_docs, title_sample)\n",
        "                    chunk_list2, chunk_tokens2 = get_chunk_tokenize(top_k2, mapper2, result_index2, sample2_raw, wiki_docs, title_sample)\n",
        "\n",
        "\n",
        "                # print(f'average tokens to answer: {len(chunk_tokens1)}')\n",
        "                chunk_sample['tokens_to_answer1'] = len(chunk_tokens1)\n",
        "                chunk_sample['tokens_to_answer2'] = len(chunk_tokens2)\n",
        "\n",
        "                # compare for sample 1 and sample 2 to get preference data.\n",
        "                if len(chunk_tokens1) < len(chunk_tokens2):\n",
        "                    chunk_sample['preference'] = 0\n",
        "                else:\n",
        "                    chunk_sample['preference'] = 1\n",
        "\n",
        "                chunking_samples.append(chunk_sample)\n",
        "                if CACHE_PREFERENCE_DATA:\n",
        "                    if len(chunk_tokens1) == len(chunk_tokens2):\n",
        "                        print('No difference deteceted, skipping save')\n",
        "                    else:\n",
        "                        # save preference data.\n",
        "                        save_preference_data(chunk_sample, chunk_count)\n",
        "\n",
        "            average_tokens_to_ans1 = sum([chunk[\"tokens_to_answer1\"] for chunk in chunking_samples])/ len(chunking_samples)\n",
        "            average_tokens_to_ans2 = sum([chunk[\"tokens_to_answer2\"] for chunk in chunking_samples]) / len(chunking_samples)\n",
        "            print(\"average_tokens_to_ans1\", average_tokens_to_ans1)\n",
        "            print(\"average_tokens_to_ans2\", average_tokens_to_ans2)\n",
        "            divergences_text, divergences_text_mask = padded_stack([chunk['divergence'][0].flatten() for chunk in chunking_samples])\n",
        "            print(f'Effective batch: {len(divergences_text)}')\n",
        "            divergences_sentence_ends_idx, divergences_sentence_ends_idx_mask = padded_stack([chunk['divergence'][1] for chunk in chunking_samples])\n",
        "            divergences_x1 = torch.tensor([chunk['divergence'][2] for chunk in chunking_samples])\n",
        "            divergences_x2 = torch.tensor([chunk['divergence'][3] for chunk in chunking_samples])\n",
        "            divergences_batched = (divergences_text, divergences_sentence_ends_idx, divergences_x1, divergences_x2)\n",
        "            preferences_batched = torch.tensor([chunk['preference'] for chunk in chunking_samples], device=device)\n",
        "            loss, sampling_entropy = train_pref(divergences_batched, divergences_text_mask, preferences_batched, model, loss_fn, opt)\n",
        "            losses.append(loss.detach().cpu().numpy())\n",
        "            losses = losses[-LOSS_WINDOW:]\n",
        "            print(f'loss: {np.mean(losses)}')\n",
        "            wandb.log({\"loss\": np.mean(losses), \"average_tokens_to_ans1\": average_tokens_to_ans1, \"average_tokens_to_ans2\": average_tokens_to_ans2,\n",
        "                       \"sampling_entropy_normalized\": sampling_entropy})\n",
        "\n",
        "            if i % 500 == 0:\n",
        "                save_checkpoint(model, opt, RUNDIR, epoch, i)\n",
        "                print('Checkpoint saved')\n",
        "\n",
        "        save_checkpoint(model, opt, RUNDIR, epoch, i)\n",
        "        print('Checkpoint saved')\n",
        "        wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Process"
      ],
      "metadata": {
        "id": "1ed1rRMaQOSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7fb5cd0d2c504a729d2740f3b8146a5a",
            "1466aa19c1a34360a9aa84e45121e576",
            "331d3d0983b94fc088063aeb5c4cd9c3",
            "b1deba56ad9440adaeae333efa5ddf1e",
            "935c96b89b554ee49bdbc14e09fe6b7f",
            "47ede3ab3a3047568cedca1a12dc6115",
            "f95327b314bc4820a8d84931a20c321b",
            "96ee16085ded4c28af4964cc7b281eb6"
          ]
        },
        "id": "w0xhPZqTGP9X",
        "outputId": "bde9fe6c-f441-4252-a428-a640f91cff5d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:0ej7ytds) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.012 MB uploaded\\r'), FloatProgress(value=0.10300925925925926, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fb5cd0d2c504a729d2740f3b8146a5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">earnest-snow-1</strong> at: <a href='https://wandb.ai/smart_chunker/smart_chunker_8_25/runs/0ej7ytds' target=\"_blank\">https://wandb.ai/smart_chunker/smart_chunker_8_25/runs/0ej7ytds</a><br/> View project at: <a href='https://wandb.ai/smart_chunker/smart_chunker_8_25' target=\"_blank\">https://wandb.ai/smart_chunker/smart_chunker_8_25</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240901_154828-0ej7ytds/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:0ej7ytds). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240901_155024-pf5jh4zw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/smart_chunker/smart_chunker_8_25/runs/pf5jh4zw' target=\"_blank\">electric-water-2</a></strong> to <a href='https://wandb.ai/smart_chunker/smart_chunker_8_25' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/smart_chunker/smart_chunker_8_25' target=\"_blank\">https://wandb.ai/smart_chunker/smart_chunker_8_25</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/smart_chunker/smart_chunker_8_25/runs/pf5jh4zw' target=\"_blank\">https://wandb.ai/smart_chunker/smart_chunker_8_25/runs/pf5jh4zw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/835 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average_tokens_to_ans1 358.0\n",
            "average_tokens_to_ans2 233.58333333333334\n",
            "Effective batch: 12\n",
            "loss: 0.6933563351631165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/835 [00:38<8:55:41, 38.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved\n",
            "average_tokens_to_ans1 250.63636363636363\n",
            "average_tokens_to_ans2 310.3636363636364\n",
            "Effective batch: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 2/835 [00:47<4:51:35, 21.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.693266749382019\n",
            "average_tokens_to_ans1 379.8\n",
            "average_tokens_to_ans2 346.9\n",
            "Effective batch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 3/835 [00:56<3:35:43, 15.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.693255603313446\n",
            "average_tokens_to_ans1 343.90909090909093\n",
            "average_tokens_to_ans2 284.90909090909093\n",
            "Effective batch: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 4/835 [01:08<3:14:35, 14.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.693230390548706\n",
            "average_tokens_to_ans1 231.45454545454547\n",
            "average_tokens_to_ans2 216.0\n",
            "Effective batch: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 5/835 [01:19<2:59:19, 12.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.6931735277175903\n",
            "average_tokens_to_ans1 290.44444444444446\n",
            "average_tokens_to_ans2 365.1111111111111\n",
            "Effective batch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 6/835 [01:28<2:40:16, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.6931214332580566\n",
            "average_tokens_to_ans1 311.0\n",
            "average_tokens_to_ans2 257.6363636363636\n",
            "Effective batch: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 7/835 [01:39<2:38:57, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.6931212544441223\n",
            "average_tokens_to_ans1 188.75\n",
            "average_tokens_to_ans2 200.125\n",
            "Effective batch: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 8/835 [01:51<2:40:29, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.6930993795394897\n",
            "average_tokens_to_ans1 258.0\n",
            "average_tokens_to_ans2 259.8333333333333\n",
            "Effective batch: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 9/835 [02:01<2:34:26, 11.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.693077027797699\n",
            "average_tokens_to_ans1 297.25\n",
            "average_tokens_to_ans2 337.5833333333333\n",
            "Effective batch: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 10/835 [02:11<2:30:32, 10.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.6929630041122437\n",
            "average_tokens_to_ans1 263.2857142857143\n",
            "average_tokens_to_ans2 307.57142857142856\n",
            "Effective batch: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 11/835 [02:18<2:10:21,  9.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.6925337314605713\n",
            "average_tokens_to_ans1 301.44444444444446\n",
            "average_tokens_to_ans2 315.0\n",
            "Effective batch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 12/835 [02:25<2:00:32,  8.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.6924245357513428\n",
            "average_tokens_to_ans1 257.3333333333333\n",
            "average_tokens_to_ans2 291.22222222222223\n",
            "Effective batch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 13/835 [02:33<1:56:54,  8.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.6921459436416626\n",
            "average_tokens_to_ans1 252.9090909090909\n",
            "average_tokens_to_ans2 313.27272727272725\n",
            "Effective batch: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 14/835 [02:44<2:05:51,  9.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.6919243931770325\n",
            "average_tokens_to_ans1 232.83333333333334\n",
            "average_tokens_to_ans2 193.08333333333334\n",
            "Effective batch: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 15/835 [02:55<2:15:22,  9.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.6919695138931274\n",
            "average_tokens_to_ans1 273.09090909090907\n",
            "average_tokens_to_ans2 259.09090909090907\n",
            "Effective batch: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 16/835 [03:06<2:20:04, 10.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.6918067336082458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 16/835 [03:08<2:40:25, 11.75s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-263240bbee7e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-44f5030c244f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0msentence_ends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_ends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0msample1_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample2_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivergence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_chunking_with_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_ends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ea657008835c>\u001b[0m in \u001b[0;36msample_chunking_with_divergence\u001b[0;34m(sentence_ends, text, answer_idx, model, device)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;31m# x = torch.multinomial(probs, 1).squeeze()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mchunk_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msentence_ends_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0msample2_single\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mcurrent_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Ap0oci9Ren6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94d9584b118b43e880c59b0ee3226d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afe49945cf554eb3a17b9d916100dfd0",
              "IPY_MODEL_2b26a675be0d4715960d66bacf9e53f5",
              "IPY_MODEL_29fc880a24164c33be6a003e9dcbfd98"
            ],
            "layout": "IPY_MODEL_7eb144d07cd44fd1aa398953f79fcbfe"
          }
        },
        "afe49945cf554eb3a17b9d916100dfd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8be62225d88c4279967d6450ab2c927c",
            "placeholder": "​",
            "style": "IPY_MODEL_2200e58948e247dcb9bfbde51d4b333d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2b26a675be0d4715960d66bacf9e53f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f1ea1bb0e2e410685af419068ccd183",
            "max": 2537,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e2a33644e524b3fb3ed504c24125c47",
            "value": 2537
          }
        },
        "29fc880a24164c33be6a003e9dcbfd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8304d959e0c34d1eae63e34f8f742735",
            "placeholder": "​",
            "style": "IPY_MODEL_d116ee67b0114c4c8f48d56139afa805",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 183kB/s]"
          }
        },
        "7eb144d07cd44fd1aa398953f79fcbfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8be62225d88c4279967d6450ab2c927c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2200e58948e247dcb9bfbde51d4b333d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f1ea1bb0e2e410685af419068ccd183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e2a33644e524b3fb3ed504c24125c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8304d959e0c34d1eae63e34f8f742735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d116ee67b0114c4c8f48d56139afa805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05bff5d46fbf4fa5938f98746eb7a9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0c6c19154ba41f983bd6fc73adeb441",
              "IPY_MODEL_cb2fab4d8f6b4d68a46b840613ffcc1d",
              "IPY_MODEL_f11d06a2b44045368d039884b9b981ff"
            ],
            "layout": "IPY_MODEL_57be918d229f44bf849dd322abf2e905"
          }
        },
        "b0c6c19154ba41f983bd6fc73adeb441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8314e3d5fed243b98059286512220b41",
            "placeholder": "​",
            "style": "IPY_MODEL_3f37ab300c104d3dae816df7c1ce7674",
            "value": "spiece.model: 100%"
          }
        },
        "cb2fab4d8f6b4d68a46b840613ffcc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb601723cae4c1c8ec79ded7fa21a24",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e8d2a70f2114b8c8e6c5f93508ff89f",
            "value": 791656
          }
        },
        "f11d06a2b44045368d039884b9b981ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41fecc42a52347dfad110764b208025d",
            "placeholder": "​",
            "style": "IPY_MODEL_f6d3fbfed9df43878d5c8ecda6d8e5e6",
            "value": " 792k/792k [00:00&lt;00:00, 10.7MB/s]"
          }
        },
        "57be918d229f44bf849dd322abf2e905": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8314e3d5fed243b98059286512220b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f37ab300c104d3dae816df7c1ce7674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fb601723cae4c1c8ec79ded7fa21a24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e8d2a70f2114b8c8e6c5f93508ff89f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41fecc42a52347dfad110764b208025d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6d3fbfed9df43878d5c8ecda6d8e5e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36db0fd0b52e43999c71cff33546b5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6e83119dc984cc48d4e02fd0846dc71",
              "IPY_MODEL_f76416c2e2d4412e97555a25fc827f52",
              "IPY_MODEL_22ef8269e9e24ec39aa86b36aebd484f"
            ],
            "layout": "IPY_MODEL_9c2b6894f2784cdebfdb75a2081eab15"
          }
        },
        "b6e83119dc984cc48d4e02fd0846dc71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1460a724714647728da30d18c16e7d70",
            "placeholder": "​",
            "style": "IPY_MODEL_772b33e902ce4f9989744a8f0dec9a52",
            "value": "tokenizer.json: 100%"
          }
        },
        "f76416c2e2d4412e97555a25fc827f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efb5655fa623444ea2b42d6578de0210",
            "max": 2424064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a02a9d5ea2144914ad7fdfc8f73cbbff",
            "value": 2424064
          }
        },
        "22ef8269e9e24ec39aa86b36aebd484f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0bf774aec714c1b81bec124a5755466",
            "placeholder": "​",
            "style": "IPY_MODEL_6f00b3f60b1c41dc81eeaff0f2d9de86",
            "value": " 2.42M/2.42M [00:00&lt;00:00, 7.38MB/s]"
          }
        },
        "9c2b6894f2784cdebfdb75a2081eab15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1460a724714647728da30d18c16e7d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "772b33e902ce4f9989744a8f0dec9a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efb5655fa623444ea2b42d6578de0210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a02a9d5ea2144914ad7fdfc8f73cbbff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0bf774aec714c1b81bec124a5755466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f00b3f60b1c41dc81eeaff0f2d9de86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0be33c32a2f94f60889a499ff1db5b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6b62398b4ca46109cc960a2017ab43c",
              "IPY_MODEL_6905298e19f7493491161f5d7bb3cda6",
              "IPY_MODEL_8fd6543fe3804e6395ddad7507e33c51"
            ],
            "layout": "IPY_MODEL_d3b2e571942f4fa2af653b1c015a2521"
          }
        },
        "f6b62398b4ca46109cc960a2017ab43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_547465d53e4248a39c3070564342ae42",
            "placeholder": "​",
            "style": "IPY_MODEL_df6c249fe14949178974d96a90c73919",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6905298e19f7493491161f5d7bb3cda6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84772da02d374caeab2a880d7e5c096c",
            "max": 2201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e9fbe81241f4f1390bd6c7ea74e0592",
            "value": 2201
          }
        },
        "8fd6543fe3804e6395ddad7507e33c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63af5b17679a4c7d9b6ab48277e1c084",
            "placeholder": "​",
            "style": "IPY_MODEL_4f24762c40f540a8a6c4770489455703",
            "value": " 2.20k/2.20k [00:00&lt;00:00, 119kB/s]"
          }
        },
        "d3b2e571942f4fa2af653b1c015a2521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "547465d53e4248a39c3070564342ae42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df6c249fe14949178974d96a90c73919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84772da02d374caeab2a880d7e5c096c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e9fbe81241f4f1390bd6c7ea74e0592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63af5b17679a4c7d9b6ab48277e1c084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f24762c40f540a8a6c4770489455703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fb5cd0d2c504a729d2740f3b8146a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1466aa19c1a34360a9aa84e45121e576",
              "IPY_MODEL_331d3d0983b94fc088063aeb5c4cd9c3"
            ],
            "layout": "IPY_MODEL_b1deba56ad9440adaeae333efa5ddf1e"
          }
        },
        "1466aa19c1a34360a9aa84e45121e576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_935c96b89b554ee49bdbc14e09fe6b7f",
            "placeholder": "​",
            "style": "IPY_MODEL_47ede3ab3a3047568cedca1a12dc6115",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "331d3d0983b94fc088063aeb5c4cd9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f95327b314bc4820a8d84931a20c321b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96ee16085ded4c28af4964cc7b281eb6",
            "value": 1
          }
        },
        "b1deba56ad9440adaeae333efa5ddf1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "935c96b89b554ee49bdbc14e09fe6b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47ede3ab3a3047568cedca1a12dc6115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f95327b314bc4820a8d84931a20c321b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ee16085ded4c28af4964cc7b281eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}